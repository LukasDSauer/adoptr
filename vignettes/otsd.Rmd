---
title: "OTSD quickstart"
author: "Kevin Kunzmann"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{quickstart}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse  = TRUE,
  comment   = "#>",
  fig.width = 8
)
library(otsd)
```

some initial design

```{r}
n1     <- 25
c1f    <-   .0
c1e    <-  2.0
n2_piv <- rep(40.0, 5)
c2_piv <- rep( 1.96, 5)

design <- FivePointDesign(n1, c1f, c1e, n2_piv, c2_piv)

z1 <- seq(-2, 4, .01)
par(mfrow = c(1, 2))
plot(z1, n(design, z1), 'l', ylim = c(0, max(n(design, z1))))
plot(z1, c2(design, z1), 'l')
```

# Define scores 

```{r}
# define null and alternative as point mass distributions
null        <- PointMassPrior(.0, 1)
alternative <- PointMassPrior(.4, 1)

dist <- Normal()

ess  <- integrate(ConditionalSampleSize(dist, alternative))
cp   <- ConditionalPower(dist, alternative)
pow  <- integrate(cp)
toer <- integrate(ConditionalPower(dist, null))

smth <- Smoothness_n2()

do.call(sprintf, 
        c(
          list("ESS: %.1f, power: %.3f, maximal type one error rate: %.3f"), 
          lapply(list(ess, pow, toer), function(s) evaluate(s, design))
        )
)
```

# Define objective

```{r}
objective <- function(x) {
  d  <- update(design, x)
  evaluate(ess, d) + .001*evaluate(smth, d)
}
objective(as.numeric(design))

constraint <- function(x) {
  d  <- update(design, x)
  c(
    .8 - evaluate(pow, d),
    evaluate(toer, d) - 0.05,
    x[2] - x[3] + .1,
    diff(c2(d, get_knots(d)))
  )
}
constraint(as.numeric(design))

ub <- c(50, 1, 4, numeric(5) + 50, numeric(5) + 5)
lb <- c(10, -1, 1, numeric(5) + 2, numeric(5) - 5)

res <- nloptr::nloptr(
  as.numeric(design),
  lb = lb,
  ub = ub,
  eval_f      = objective,
  eval_g_ineq = constraint,
  opts = list(
    algorithm   = "NLOPT_LN_COBYLA",
    xtol_rel    = 1e-4,
    maxeval     = 2500
  )
)

d2 <- update(design, res$solution)
par(mfrow = c(1, 2))
plot(z1, n(d2, z1), 'l', ylim = c(0, max(n(d2, z1))))
plot(z1, c2(d2, z1), 'l')
```

Compute the scores using fast internal representation (5-point Newton-Cotes).

```{r}
do.call(sprintf, 
        c(
          list("ESS: %.1f, power: %.3f, maximal type one error rate: %.3f"), 
          lapply(list(ess, pow, toer), function(s) evaluate(s, d2, specific = TRUE))
        )
)
```

Compute the scores using adaptive quadrature rules (increased precision but slow).

```{r}
do.call(sprintf, 
        c(
          list("ESS: %.1f, power: %.3f, maximal type one error rate: %.3f"), 
          lapply(list(ess, pow, toer), function(s) evaluate(s, d2, specific = FALSE))
        )
)
```


okay, so what changes when we use a continuous prior instead?


```{r}
f <- function(x) dnorm(x, .5, .2)
limits <- c(0, 1)
z   <- stats::integrate(f, limits[1], limits[2], abs.tol = .0001)$value
pdf <- function(x) f(x) / z
alternative <- ContinuousPrior(pdf, limits)

ess  <- integrate(ConditionalSampleSize(dist, alternative))

# just for the fun of it lets condition on detla >= .1
alternative_cond <- condition(alternative, c(.1, 1.))
cp   <- ConditionalPower(dist, alternative_cond)
pow  <- integrate(cp)
toer <- integrate(ConditionalPower(dist, null))

smth <- Smoothness_n2()

do.call(sprintf, 
        c(
          list("ESS: %.1f, power: %.3f, maximal type one error rate: %.3f"), 
          lapply(list(ess, pow, toer), function(s) evaluate(s, design))
        )
)
```

CP power constraints!

```{r}
objective <- function(x) {
  d  <- update(design, x)
  evaluate(ess, d) + .001*evaluate(smth, d)
}
objective(as.numeric(design))

constraint <- function(x) {
  d  <- update(design, x)
  c(
    .8 - evaluate(pow, d),
    evaluate(toer, d) - 0.05,
    x[2] - x[3] + .25,
    diff(c2(d, get_knots(d))),
    .7 - evaluate(cp, d, get_knots(d))
  )
}
constraint(as.numeric(design))

ub <- c(50, 1, 4, numeric(5) + 50, numeric(5) + 5)
lb <- c(10, -1, 1, numeric(5) + 2, numeric(5) - 5)

res <- nloptr::nloptr(
  as.numeric(design),
  lb = lb,
  ub = ub,
  eval_f      = objective,
  eval_g_ineq = constraint,
  opts = list(
    algorithm   = "NLOPT_LN_COBYLA",
    xtol_rel    = 1e-4,
    maxeval     = 2500
  )
)

d2 <- update(design, res$solution)
par(mfrow = c(1, 3))
plot(z1, n(d2, z1), 'l', ylim = c(0, max(n(d2, z1))))
plot(z1, c2(d2, z1), 'l')
plot(z1, evaluate(cp, d2, z1), 'l')
```
