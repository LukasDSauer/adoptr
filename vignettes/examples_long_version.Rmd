---
title: "otsd examples"
author: "Maximilian Pilz"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{examples}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse  = TRUE,
  eval = FALSE,
  comment   = "#>",
  fig.width = 8
)
```

# Introduction

Blabla 

# General setup

We assume a two sample clinical trial with normally distributed outcomes and
known variance $\sigma^2$. 

BESCHREIBUNG DER SITUATION

To start we install and load the package by
```{r load package, echo = F}
#devtools::install_github("kkmann/otsd")
library(otsd)
```

At first we specify the distribution of the data and that a two-armed trial
is regarded

```{r normal distribution}
dist <- Normal(two_armed = TRUE)
```

This distritbution will be used during the next examples. 
Until now only the normal distribution case is implemented. 
A further extension to $t$-distribution, the two-sample binomial test for 
binary data and the logrank test for survival data is planned.


The package allows to compute optimal designs for different effect sizes
and for different discrete as continuous prior distributions. 
According to the ICH E9 guidline the type one error rate protection in a 
clinical trial is of highest importance. 
To make the grade we focus on a point null hypothesis with mass $1$ on the
effect size $\delta = 0$. Since the complete procedure is translation invariant
it can easily be adapted to different null hypothesis. 
We can specify the null hypothesis as `PointMassPrior` with all 
probability mass on the singe point $\delta =0$:

```{r null hypothesis}
null = PointMassPrior(0, 1)
```

Furthermore, the type one error rate is introduced as probability to reject
the null hypothesis when the null hypothesis holds true. This
is nothing else but the integrated conditional power under the null hypothesis.

```{r toer}
toer = integrate(ConditionalPower(dist, null))
```

In the following the usage of the package is illustrated on different examples
which are based on the assumptions made above.
There are two scenarios that will be investigated. 
In the first scenario we assume an effect size of $\delta_1 = .4$ as expected 
effect size under the alternative hypothesis. 
To demonstrate the optimization on two different effect sizes,
in the second scenario the smaller effect size $\delta_2 = .2$ is investigated.
It is illustrated how varying the  optimization criterion and a potential 
incorporation of a continuous prior influences the resulting optimal design. 
[VIELLEICHT DOCH NUR EIN SZENARIO UND KLEINERER EFFEKT DANN UNTEN??]

# The classical setting

Classically, one is assuming a point alternative hypothesis and is
interested in minimizing the expected sample size under the alternative 
hypothesis while protecting the type one error rate at level $\alpha \in (0,1)$
and a certain power of $1-\beta$.
Regarding the formula for power and expected sample size yields:
$$
\text{Power}_{\delta_1} = \int_{c_f}^{c_e} \text{CP}_{\delta_1}(z_1) f_{\delta_1}(z_1) \operatorname{d}z_1.\\
\text{ESS}_{\delta_1} = \int_{c_f}^{c_e} \text{CSS}_{\delta_1}(z_1) f_{\delta_1}(z_1) \operatorname{d}z_1.
$$
Here, $\operatorname{CP}$ and $\operatorname{CSS}$ denote the conditional power
and the conditional sample size, respectively, and $f_{\delta_1}$ is the 
density of the normal distribution under the effect size $\delta_1$..
The package `otsd` provides an integration method to integrate 
conditional measures under a specified distribution. 
Therefore, the alternative hypothesis, the power and the expected sample size
under the alternative can be introduced as
```{r}
alternative <- PointMassPrior(.4, 1)
pow         <- integrate(ConditionalPower(dist, alternative))
ess         <- integrate(ConditionalSampleSize(dist, alternative))
```

Now, all the key figures are defined and the problem
$$ 
 \min  \text{Expected Sample Size under } \mathcal{H}_1 \\
 \text{s.t.}  \text{Type One Error Rate} \leq \alpha \\
\text{Power } \geq 1 - \beta
$$
can be solved. We use the typical values $\alpha=0.025$ and $\beta = 0.2$ 
for the error rate constraints.

The last step that has to be done is to predefine an initial design, i.e.
a starting value for the optimization.
`otsd` contains a function `gq_design` that creates designs which
are usable for optimization because their stage-two functions are 
approximated via a finite set of pivots and integration over
this functions is performed via Gaussian quadrature. 
`order` defines the grade of the integration rule. 
For many problems, setting order to $5$ suffices to produce sensitive solutions.
However, for sake of illustration, we used a larger value here. 
It should be noted that two high values make the problem hard to solve
in a smooth manner because there are two many paramters in this case.
Therefore, we recommend a value of $5$ for "quick" optimization and $9$ 
when the results should be very precise.

```{r}
order = 5L # maybe find a default here

design <- gq_design(
    n1  = 50,
    c1f = .0,
    c1e = 2.0,
    n2  = seq(200, 20, length.out = order),
    c2  = rep(1.96, order),
    order = order)
```

```{r}
smth <- integrate(SmoothnessN2(dist)) #in minimize??
```

Now, an optimal_design can be computed by means of
the `minimize` function. 
The lower and upper bounds for the design that is to be optimized
are 

```{r, warning = F}
minimize(
    objective = ess + 1e-6*smth,
    subject_to(
        pow  >= 0.8,
        toer <= 0.025
    ),
    initial_design = design,
    lower_boundary_design = update(design, c(10, -2, 2, numeric(order) + 2, numeric(order) - 3)),
    upper_boundary_design = update(design, c(500, 2, 5, numeric(order) + 500, numeric(order) + 3))

) ->
    optimal_design
```

`otsd` provides summary and plotting methods for two-stage designs.
In the `plot` function the discretness of $n_2$ is already incorporated.
This makes the plots of the sample size and the conditional power 
a little bit stepwise. In the section about post processing we analyse
this point more detailed.
The results are illustrated by these functions.
```{r}
plot(optimal_design, "Conditional Power" = ConditionalPower(dist, alternative))
```

```{r}
summary(optimal_design, "Power" = pow, "Type One Error" = toer)
```

The results look as one may have expected. The stage-two functions are
monotonouesly decreasing and the error rates are fulfilled with equality. 

# Change of the performance criterion

Instead of minimizing the sample size under the alternative hypothesis one 
could also strive after finding the design with the lowest sample size under
the null hypothesis. 
This can easily be incorprated in the presented setting by changing
the performance criterion.

```{r}
ess_0 <- integrate(ConditionalSampleSize(dist, null))
```

This slight allows to look for the optimal design in terms of expected sample
size under the null hypothesis.
Since the constraints are not changed, the above definitions can still be used.

```{r, warning = F}
minimize(
    objective = ess_0 + 1e-6*smth,
    subject_to(
        pow  >= 0.8,
        toer <= 0.025
    ),
    initial_design = design,
    lower_boundary_design = update(design, c(10, -2, 2, numeric(order) + 2, numeric(order) - 1)),
    upper_boundary_design = update(design, c(500, 2, 5, numeric(order) + 500, numeric(order) + 3)),
    opts = list(algorithm   = "NLOPT_LN_COBYLA",
                xtol_rel    = 1e-4,
                maxeval     = 5000)

) ->
    optimal_design_2
```

Again, the resulting design can be illustrated by using the `plot`
and `summary` functions. 

```{r}
plot(optimal_design_2, "Conditional Power" = ConditionalPower(dist, alternative))
```

```{r}
summary(optimal_design_2, "Power" = pow, "Type One Error" = toer)
```

The changes to the previous situation are enormously. 
While previously the $n_2$-function was concave and monotonously decreasing
it is now increasing until a certain $z_1$ value and then decreasing. 
Furthermore, the efficacy bound $c_e$ becomes very large because
large values of $z_1$ are very unlikely under the null hypothesis and 
do therefore hardly impact the expected sample size.
The $c_2$ function is convex while $n_2$ is increasing and changes then 
to concave when $n_2$ decreases.

# Incorporation of a continuous prior

## A Gaussian prior

As next step the uncertainty of the true effect size can be reflected by 
incorporating a continuous prior. 
For instance, a Gaussian prior with mean $\mu = 0.4$ and a small standard 
deviation of $\tau = 0.1$ can be used. 
It is necessary to define the support of the prior in order to avoid
numerical errors by integrating over an infinite parameter space.
Here, the supprt $[-0.5, 1.5]$ is chosen. 
If the integral of the prior density on the support did not equal to $1$
the package would return an error message.

However, one should remind that integrating over the whole paramater
space does not imply a consistent definition of power anymore because
all effect sizes $\delta \leq 0$ are part of the null hypothesis. 
Therefore, to define the alternative hypothesis the prior
is conditioned on non-negative effect sizes. 

```{r}
density_1   <- function(x) dnorm(x, mean = .4, sd = .2)
prior       <- ContinuousPrior(density_1, c(-.7, 1.6))
alternative <- condition(prior, c(0, 1.6))
```

This requires a new definition of the power and the objective function.
The power can again be defined as integral over the conditional power due
to the object-orientated character of the package.
As objective function the expected sample size on the whole parameter space
is regarded.

```{r}
pow <- integrate(ConditionalPower(dist, alternative))

ess_total <- integrate(ConditionalSampleSize(dist, prior))
```

These changes are sufficient to compute the new optimal design
by again calling the `minimize` function.

```{r, warning = F}
minimize(
    objective = ess_total + 1e-6*smth,
    subject_to(
        pow  >= 0.8,
        toer <= 0.025
    ),
    initial_design = design,
    lower_boundary_design = update(design, c(10, -2, 2, numeric(order) + 2, numeric(order) - 1)),
    upper_boundary_design = update(design, c(500, 2, 5, numeric(order) + 500, numeric(order) + 3)),
    opts = list(algorithm   = "NLOPT_LN_COBYLA",
                xtol_rel    = 1e-4,
                maxeval     = 10000)

) ->
    optimal_design_3
```


```{r}
plot(optimal_design_3, "Conditional Power" = ConditionalPower(dist, alternative))
```

```{r}
summary(optimal_design_3, "Power" = pow, "Type One Error" = toer)
```

The optimal design does hardly differ from the one with a point mass prior
and with expected sample size under the alternative. 
This holds true due to the fact that the prior variance of $\tau = .1$ is quite
small and therefore, there is almost no probability mass on the null hypothesis
and the probability mass is concentrated around $\delta = 0.4$. 


## A uniform prior

In this section the situation is investigated that the expected effect 
size remains $\delta = 0.4$ while all effect sizes $\delta \geq 0.2$ are
clinically relevant and of interest. However, effect sizes larger
than $\delta = 0.6$ seem unrealistic. 
Therefore, a uniform prior on the interval $[0.2, 0.6]$ is used for this
situation. 
Note that in this example no conditioning is necessary because the 
effect sizes are already larger than the null hypothesis effect sizes $\delta=0$.

```{r}
density_2   <- function(x) dunif(x, min = 0.2, max = 0.6)
prior_2     <- ContinuousPrior(density_2, support = c(0.2, 0.6))
```

For the same reason it does not matter whether one is regarding the expected
sample size on the whole parameter space or on the alternative hypothesis
because there is no prior probability mass outside the interval $[0.2, 0.6]$.

```{r}
pow <- integrate(ConditionalPower(dist, prior_2))

ess <- integrate(ConditionalSampleSize(dist, prior_2))
```

These changes are sufficient to compute the new optimal design
by again calling the `minimize` function.

```{r, warning = F}
minimize(
    objective = ess + 1e-6*smth,
    subject_to(
        pow  >= 0.8,
        toer <= 0.025
    ),
    initial_design = design,
    lower_boundary_design = update(design, c(10, -2, 2, numeric(order) + 2, numeric(order) - 1)),
    upper_boundary_design = update(design, c(500, 2, 5, numeric(order) + 500, numeric(order) + 3)),
    opts = list(algorithm   = "NLOPT_LN_COBYLA",
                xtol_rel    = 1e-4,
                maxeval     = 5000)

) ->
    optimal_design_4
```


```{r}
plot(optimal_design_4, "Conditional Power" = ConditionalPower(dist, prior_2))
```

```{r}
summary(optimal_design_4, "Power" = pow, "Type One Error" = toer)
```

There is again no big difference to the classical situation. 
The first-stage sample size becomes smaller for the price of a larger 
continuation region $[c_f, c_e]$. One can observe that when the null hypothesis
is not used as reference for the optimization, the optimal function $n_2$ 
stays monotonously decreasing. 


# Additional features

In this section some additional properties of the package `adoptr` are presented.
We return to the classical setting of a point mass prior and investigate
the influence of adding conditional inequalities or defining a new performance
criterion. 
To this end, we return to the initial situation by defining 
the alternative and the expected sample size under the alternative
as in the first section.
```{r}
alternative <- PointMassPrior(.4, 1)
pow         <- integrate(ConditionalPower(dist, alternative))
ess         <- integrate(ConditionalSampleSize(dist, alternative))
```


## Conditional power constraints
To trial sponsors it is often hardly acceptable to conduct the second-stage
of a trial without a sufficient conditional power. 
`adoptr` allows to implement conditional constraints as, e.g., 
requiering the conditional power to be above a certain level. 
We extend the first example that was regarded by a conditional power constraint
of 75\%.

```{r}
cp <- ConditionalPower(dist, alternative)
```

```{r, warning = F}
minimize(
    objective = ess + 1e-6*smth,
    subject_to(
        pow  >= 0.8,
        toer <= 0.025,
        cp   >= 0.75
    ),
    initial_design = design,
    lower_boundary_design = update(design, c(10, -2, 2, numeric(order) + 2, numeric(order) - 1)),
    upper_boundary_design = update(design, c(500, 2, 5, numeric(order) + 500, numeric(order) + 3)),
    opts = list(algorithm   = "NLOPT_LN_COBYLA",
                xtol_rel    = 1e-4,
                maxeval     = 5000)

) ->
    optimal_design_5
```


```{r}
plot(optimal_design_5, "Conditional Power" = ConditionalPower(dist, alternative))
```

```{r}
summary(optimal_design_5, "Power" = pow, "Type One Error" = toer)
```


## Definition of new performance measure

## Compute optimal second stage

## Error rate protection by post processing

## Checking scores with simulate



